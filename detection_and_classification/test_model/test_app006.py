import torch  
import torchvision  
from torchvision.models.detection import FasterRCNN  
from torchvision.models.detection.rpn import AnchorGenerator  
import cv2  
import numpy as np  
import matplotlib.pyplot as plt  
from collections import Counter  

class VehicleDetector:  
    def __init__(self):  
        """  
        Kh·ªüi t·∫°o detector s·ª≠ d·ª•ng Faster R-CNN  
        """  
        # Ki·ªÉm tra GPU  
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  
        print(f"üñ•Ô∏è ƒêang s·ª≠ d·ª•ng: {self.device}")  
        
        # Load m√¥ h√¨nh Faster R-CNN  
        self.model = self._load_faster_rcnn()  
        self.model.to(self.device)  
        self.model.eval()  
        
        # Danh m·ª•c xe chi ti·∫øt  
        self.vehicle_categories = {  
            'personal': ['car', 'sedan', 'suv', 'hatchback'],  
            'commercial': ['truck', 'van', 'bus', 'pickup'],  
            'two_wheel': ['motorcycle', 'bicycle'],  
            'heavy': ['lorry', 'trailer']  
        }  
    
    def _load_faster_rcnn(self):  
        """  
        T·∫£i m√¥ h√¨nh Faster R-CNN  
        """  
        # Load backbone ResNet50  
        backbone = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)  
        backbone = torch.nn.Sequential(*list(backbone.children())[:-2])  
        backbone.out_channels = 2048  
        
        # T·∫°o anchor generator  
        anchor_generator = AnchorGenerator(  
            sizes=((32, 64, 128, 256, 512),),  
            aspect_ratios=((0.5, 1.0, 2.0),) * 5  
        )  
        
        # T·∫°o m√¥ h√¨nh Faster R-CNN  
        model = FasterRCNN(  
            backbone,  
            num_classes=91,  # COCO dataset c√≥ 90 classes + background  
            rpn_anchor_generator=anchor_generator  
        )  
        
        return model  
    
    def detect_and_count_vehicles(self, image_path, confidence_threshold=0.5):  
        """  
        Ph√°t hi·ªán v√† ƒë·∫øm xe v·ªõi Faster R-CNN  
        """  
        try:  
            # ƒê·ªçc ·∫£nh  
            image = cv2.imread(image_path)  
            if image is None:  
                raise ValueError(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·ª´ {image_path}")  
            
            # Chuy·ªÉn ƒë·ªïi ·∫£nh sang tensor  
            image_tensor = self._preprocess_image(image)  
            
            # D·ª± ƒëo√°n  
            with torch.no_grad():  
                predictions = self.model(image_tensor)  
            
            # L∆∞u tr·ªØ k·∫øt qu·∫£  
            detected_vehicles = []  
            vehicle_counts = {  
                'total': 0,  
                'by_category': {  
                    'personal': 0,  
                    'commercial': 0,  
                    'two_wheel': 0,  
                    'heavy': 0  
                },  
                'detailed_count': {}  
            }  
            
            # X·ª≠ l√Ω k·∫øt qu·∫£  
            for box, label, score in zip(  
                predictions[0]['boxes'],  
                predictions[0]['labels'],  
                predictions[0]['scores']  
            ):  
                if score >= confidence_threshold:  
                    label_name = self._get_label_name(label.item())  
                    
                    # Ph√¢n lo·∫°i  
                    for category, classes in self.vehicle_categories.items():  
                        if label_name.lower() in classes:  
                            detected_vehicles.append({  
                                'class': label_name,  
                                'category': category,  
                                'confidence': score.item(),  
                                'bbox': box.cpu().numpy().astype(int)  
                            })  
                            
                            # C·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng  
                            vehicle_counts['total'] += 1  
                            vehicle_counts['by_category'][category] += 1  
                            vehicle_counts['detailed_count'][label_name] = \
                                vehicle_counts['detailed_count'].get(label_name, 0) + 1  
                            break  
            
            return {  
                'image': cv2.cvtColor(image, cv2.COLOR_BGR2RGB),  
                'vehicles': detected_vehicles,  
                'counts': vehicle_counts  
            }  
        
        except Exception as e:  
            print(f"‚ùå L·ªói nh·∫≠n di·ªán: {e}")  
            return None  
    
    def _preprocess_image(self, image):  
        """  
        Ti·ªÅn x·ª≠ l√Ω ·∫£nh tr∆∞·ªõc khi ƒë∆∞a v√†o m√¥ h√¨nh  
        """  
        # Chuy·ªÉn ·∫£nh sang tensor  
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  
        image = image.astype(np.float32) / 255.0  
        image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)  
        return image.to(self.device)  
    
    def _get_label_name(self, label_id):  
        """  
        L·∫•y t√™n class t·ª´ ID  
        """  
        # S·ª≠ d·ª•ng COCO dataset labels  
        coco_labels = [  
            'unlabeled', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',   
            'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',   
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella',   
            'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',   
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate',   
            'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',   
            'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror',   
            'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',   
            'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase',   
            'scissors', 'teddy bear', 'hair drier', 'toothbrush'  
        ]  
        return coco_labels[label_id] if label_id < len(coco_labels) else 'unknown'  
    
    def visualize_detection(self, detection_result):  
        """  
        Tr·ª±c quan h√≥a k·∫øt qu·∫£ nh·∫≠n di·ªán  
        """  
        if detection_result is None:  
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã")  
            return  
        
        plt.figure(figsize=(16, 7))  
        
        # ·∫¢nh nh·∫≠n di·ªán  
        plt.subplot(121)  
        plt.imshow(detection_result['image'])  
        plt.title('Nh·∫≠n Di·ªán Xe')  
        
        # V·∫Ω bounding box  
        for vehicle in detection_result['vehicles']:  
            bbox = vehicle['bbox']  
            plt.gca().add_patch(plt.Rectangle(  
                (bbox[0], bbox[1]),   
                bbox[2] - bbox[0],   
                bbox[3] - bbox[1],   
                fill=False,   
                edgecolor='red',   
                linewidth=2  
            ))  
            plt.text(  
                bbox[0], bbox[1]-10,   
                f"{vehicle['class']} ({vehicle['confidence']:.2f})",   
                color='red'  
            )  
        
        # Bi·ªÉu ƒë·ªì th·ªëng k√™  
        plt.subplot(122)  
        counts = detection_result['counts']['detailed_count']  
        plt.bar(counts.keys(), counts.values())  
        plt.title('Th·ªëng K√™ Lo·∫°i Xe')  
        plt.xticks(rotation=45)  
        
        plt.tight_layout()  
        plt.show()  
    
    def generate_traffic_report(self, detection_result):  
        """  
        T·∫°o b√°o c√°o chi ti·∫øt  
        """  
        if detection_result is None:  
            return "‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu b√°o c√°o"  
        
        counts = detection_result['counts']  
        
        report = f"""  
        üöó B√ÅO C√ÅO TH·ªêNG K√ä PH∆Ø∆†NG TI·ªÜN  
        -------------------------------  
        T·ªïng s·ªë ph∆∞∆°ng ti·ªán: {counts['total']}  
        
        Ph√¢n lo·∫°i:  
        - Xe c√° nh√¢n: {counts['by_category']['personal']}  
        - Xe th∆∞∆°ng m·∫°i: {counts['by_category']['commercial']}  
        - Xe hai b√°nh: {counts['by_category']['two_wheel']}  
        - Xe t·∫£i n·∫∑ng: {counts['by_category']['heavy']}  
        
        Chi ti·∫øt t·ª´ng lo·∫°i:  
        {chr(10).join(f"- {xe}: {s·ªë_l∆∞·ª£ng}" for xe, s·ªë_l∆∞·ª£ng in counts['detailed_count'].items())}  
        """  
        
        return report  

# H√†m main ƒë·ªÉ ch·∫°y  
def main():  
    try:  
        # T·∫°o detector  
        detector = VehicleDetector()  
        
        # ƒê∆∞·ªùng d·∫´n ·∫£nh   
        image_path = 'data_test/test_image001.jpg'  
        
        # Nh·∫≠n di·ªán xe  
        detection = detector.detect_and_count_vehicles(image_path)  
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£  
        detector.visualize_detection(detection)  
        
        # In b√°o c√°o  
        print(detector.generate_traffic_report(detection))  
    
    except Exception as e:  
        print(f"‚ùå L·ªói ch∆∞∆°ng tr√¨nh: {e}")  

# Ch·∫°y ch√≠nh  
if __name__ == "__main__":  
    main()  